# @package _group_

batch_size: 50
gradient_accumulation_steps: 1
num_train_epochs: 5
eval_epochs: 1

hard_negatives: 0
other_negatives: 1
shared_encoder: False # false
p_max_length: 256
q_max_length: 150
warmup_rate: 0.1
train_insert_title: True # False
valid_insert_title: True # nq_dev

adam_eps: 1e-8
adam_betas: (0.9, 0.999)
learning_rate: 2e-5
max_grad_norm: 2.0
log_batch_step: 100
train_rolling_loss_step: 100
weight_decay: 0.0
val_av_rank_hard_neg: 30
val_av_rank_other_neg: 30
val_av_rank_bsz: 128
val_av_rank_max_qs: 10000
dev_batch_size: 16




